{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 불러오기"
      ],
      "metadata": {
        "id": "MLvmk2Nd2fkI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNKoof-D0PSP",
        "outputId": "a35b8f1f-556e-4698-f236-755e5fc86471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/cardiovascular-disease-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"sulianova/cardiovascular-disease-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "fUjNbgxw363A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 전체 경로 지정\n",
        "csv_path = os.path.join(path, \"cardio_train.csv\")\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv(csv_path, sep=';')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP14ysfo1Btn",
        "outputId": "918f1e95-9b66-40a6-b9ba-aceb04c5333a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
            "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
            "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
            "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
            "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
            "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
            "\n",
            "   alco  active  cardio  \n",
            "0     0       1       0  \n",
            "1     0       1       1  \n",
            "2     0       0       1  \n",
            "3     0       1       1  \n",
            "4     0       0       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUaoGqgp1QsJ",
        "outputId": "edb11036-36e2-4561-d4af-e06b9a1df607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 70000 entries, 0 to 69999\n",
            "Data columns (total 13 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   id           70000 non-null  int64  \n",
            " 1   age          70000 non-null  int64  \n",
            " 2   gender       70000 non-null  int64  \n",
            " 3   height       70000 non-null  int64  \n",
            " 4   weight       70000 non-null  float64\n",
            " 5   ap_hi        70000 non-null  int64  \n",
            " 6   ap_lo        70000 non-null  int64  \n",
            " 7   cholesterol  70000 non-null  int64  \n",
            " 8   gluc         70000 non-null  int64  \n",
            " 9   smoke        70000 non-null  int64  \n",
            " 10  alco         70000 non-null  int64  \n",
            " 11  active       70000 non-null  int64  \n",
            " 12  cardio       70000 non-null  int64  \n",
            "dtypes: float64(1), int64(12)\n",
            "memory usage: 6.9 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cardio 0,1 비율확인\n",
        "#불균형시 다른 처리 필요할 수 있음]\n",
        "#해당 데이터는 거의 5;5로 균형잡힌 데이터\n",
        "\n",
        "print(df['cardio'].value_counts())\n",
        "print(df['cardio'].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "Qi5mg9zu6ess",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f11b325-d100-450c-81b2-9a2840abf141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardio\n",
            "0    35021\n",
            "1    34979\n",
            "Name: count, dtype: int64\n",
            "cardio\n",
            "0    0.5003\n",
            "1    0.4997\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. 전처리"
      ],
      "metadata": {
        "id": "KRt2tkp63JL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 결측치는 이미 없어서 생략\n",
        "#2. 이상치 처리\n",
        "#나이가 일수로 되어있어 년수로 바꿈\n",
        "df['age'] = (df['age'] / 365).astype(int)\n",
        "df['age']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "fGqSJz3i3MWV",
        "outputId": "763791dd-ca1a-41fc-9971-351e68e4d361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        50\n",
              "1        55\n",
              "2        51\n",
              "3        48\n",
              "4        47\n",
              "         ..\n",
              "69995    52\n",
              "69996    61\n",
              "69997    52\n",
              "69998    61\n",
              "69999    56\n",
              "Name: age, Length: 70000, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#혈압 너무 높거나 작으면 이상치이니 정상범주만 셀렉\n",
        "df = df[(df['ap_hi'] > 50) & (df['ap_hi'] < 250)]\n",
        "df = df[(df['ap_lo'] > 30) & (df['ap_lo'] < 200)]"
      ],
      "metadata": {
        "id": "134k5FSF4Icc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#비현실적인 키/몸무게 제거\n",
        "df = df[(df['height'] > 100) & (df['height'] < 250)]\n",
        "df = df[(df['weight'] > 30) & (df['weight'] < 250)]"
      ],
      "metadata": {
        "id": "MX8HbM0g4cls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BMI 파생 변수 추가\n",
        "df['BMI'] = df['weight'] / ((df['height'] / 100) ** 2)"
      ],
      "metadata": {
        "id": "2GtASK304fj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9wBO8uc74obC",
        "outputId": "cb5fca02-990b-42a3-9502-b1e032f785bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  \\\n",
              "0          0   50       2     168    62.0    110     80            1     1   \n",
              "1          1   55       1     156    85.0    140     90            3     1   \n",
              "2          2   51       1     165    64.0    130     70            3     1   \n",
              "3          3   48       2     169    82.0    150    100            1     1   \n",
              "4          4   47       1     156    56.0    100     60            1     1   \n",
              "...      ...  ...     ...     ...     ...    ...    ...          ...   ...   \n",
              "69995  99993   52       2     168    76.0    120     80            1     1   \n",
              "69996  99995   61       1     158   126.0    140     90            2     2   \n",
              "69997  99996   52       2     183   105.0    180     90            3     1   \n",
              "69998  99998   61       1     163    72.0    135     80            1     2   \n",
              "69999  99999   56       1     170    72.0    120     80            2     1   \n",
              "\n",
              "       smoke  alco  active  cardio        BMI  \n",
              "0          0     0       1       0  21.967120  \n",
              "1          0     0       1       1  34.927679  \n",
              "2          0     0       0       1  23.507805  \n",
              "3          0     0       1       1  28.710479  \n",
              "4          0     0       0       0  23.011177  \n",
              "...      ...   ...     ...     ...        ...  \n",
              "69995      1     0       1       0  26.927438  \n",
              "69996      0     0       1       1  50.472681  \n",
              "69997      0     1       0       1  31.353579  \n",
              "69998      0     0       0       1  27.099251  \n",
              "69999      0     0       1       0  24.913495  \n",
              "\n",
              "[68736 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97ecd274-ea1d-4876-bd80-b28675360b70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>ap_hi</th>\n",
              "      <th>ap_lo</th>\n",
              "      <th>cholesterol</th>\n",
              "      <th>gluc</th>\n",
              "      <th>smoke</th>\n",
              "      <th>alco</th>\n",
              "      <th>active</th>\n",
              "      <th>cardio</th>\n",
              "      <th>BMI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>62.0</td>\n",
              "      <td>110</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>21.967120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>85.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.927679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64.0</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>23.507805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>169</td>\n",
              "      <td>82.0</td>\n",
              "      <td>150</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>28.710479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>56.0</td>\n",
              "      <td>100</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.011177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>99993</td>\n",
              "      <td>52</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>76.0</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.927438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>99995</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>126.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50.472681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>99996</td>\n",
              "      <td>52</td>\n",
              "      <td>2</td>\n",
              "      <td>183</td>\n",
              "      <td>105.0</td>\n",
              "      <td>180</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>31.353579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>99998</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>72.0</td>\n",
              "      <td>135</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>27.099251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>99999</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>72.0</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24.913495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68736 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97ecd274-ea1d-4876-bd80-b28675360b70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97ecd274-ea1d-4876-bd80-b28675360b70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97ecd274-ea1d-4876-bd80-b28675360b70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c9ef1304-1f98-4160-8d89-d16744a46ab3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9ef1304-1f98-4160-8d89-d16744a46ab3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c9ef1304-1f98-4160-8d89-d16744a46ab3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_03fb0275-5a25-493c-8609-46dd13e6e09e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_03fb0275-5a25-493c-8609-46dd13e6e09e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 68736,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28845,\n        \"min\": 0,\n        \"max\": 99999,\n        \"num_unique_values\": 68736,\n        \"samples\": [\n          16257,\n          19941,\n          37136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 29,\n        \"max\": 64,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          39,\n          41,\n          40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 104,\n        \"max\": 207,\n        \"num_unique_values\": 83,\n        \"samples\": [\n          167,\n          168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.304111389682646,\n        \"min\": 31.0,\n        \"max\": 200.0,\n        \"num_unique_values\": 273,\n        \"samples\": [\n          50.0,\n          128.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap_hi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 60,\n        \"max\": 240,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          107,\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap_lo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 40,\n        \"max\": 190,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          111,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cholesterol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gluc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoke\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alco\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"active\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cardio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.341967696971008,\n        \"min\": 10.726643598615919,\n        \"max\": 152.55177514792896,\n        \"num_unique_values\": 3744,\n        \"samples\": [\n          48.21996511747205,\n          19.05197378448407\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#카테고리형 변수 정리\n",
        "#cholesterol, gluc (1:정상, 2:높음, 3:매우 높음)\n",
        "#smoke, alco, active, gender (이진값)\n",
        "#범주형 변수라면 원핫 인코딩(One-Hot Encoding)이나 레이블 인코딩이 필요\n",
        "\n",
        "df = pd.get_dummies(df, columns=['cholesterol', 'gluc'], drop_first=True)"
      ],
      "metadata": {
        "id": "dno5vP2E4qFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "91yFNBYg7ZUE",
        "outputId": "34d1ad69-08ad-489d-8d90-b31b6da7e446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  age  gender  height  weight  ap_hi  ap_lo  smoke  alco  active  \\\n",
              "0          0   50       2     168    62.0    110     80      0     0       1   \n",
              "1          1   55       1     156    85.0    140     90      0     0       1   \n",
              "2          2   51       1     165    64.0    130     70      0     0       0   \n",
              "3          3   48       2     169    82.0    150    100      0     0       1   \n",
              "4          4   47       1     156    56.0    100     60      0     0       0   \n",
              "...      ...  ...     ...     ...     ...    ...    ...    ...   ...     ...   \n",
              "69995  99993   52       2     168    76.0    120     80      1     0       1   \n",
              "69996  99995   61       1     158   126.0    140     90      0     0       1   \n",
              "69997  99996   52       2     183   105.0    180     90      0     1       0   \n",
              "69998  99998   61       1     163    72.0    135     80      0     0       0   \n",
              "69999  99999   56       1     170    72.0    120     80      0     0       1   \n",
              "\n",
              "       cardio        BMI  cholesterol_2  cholesterol_3  gluc_2  gluc_3  \n",
              "0           0  21.967120          False          False   False   False  \n",
              "1           1  34.927679          False           True   False   False  \n",
              "2           1  23.507805          False           True   False   False  \n",
              "3           1  28.710479          False          False   False   False  \n",
              "4           0  23.011177          False          False   False   False  \n",
              "...       ...        ...            ...            ...     ...     ...  \n",
              "69995       0  26.927438          False          False   False   False  \n",
              "69996       1  50.472681           True          False    True   False  \n",
              "69997       1  31.353579          False           True   False   False  \n",
              "69998       1  27.099251          False          False    True   False  \n",
              "69999       0  24.913495           True          False   False   False  \n",
              "\n",
              "[68736 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-497ffb19-2565-4984-b8cf-3e7d066dacd0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>ap_hi</th>\n",
              "      <th>ap_lo</th>\n",
              "      <th>smoke</th>\n",
              "      <th>alco</th>\n",
              "      <th>active</th>\n",
              "      <th>cardio</th>\n",
              "      <th>BMI</th>\n",
              "      <th>cholesterol_2</th>\n",
              "      <th>cholesterol_3</th>\n",
              "      <th>gluc_2</th>\n",
              "      <th>gluc_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>62.0</td>\n",
              "      <td>110</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>21.967120</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>85.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.927679</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64.0</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>23.507805</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>169</td>\n",
              "      <td>82.0</td>\n",
              "      <td>150</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>28.710479</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>56.0</td>\n",
              "      <td>100</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.011177</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>99993</td>\n",
              "      <td>52</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>76.0</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.927438</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>99995</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>126.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50.472681</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>99996</td>\n",
              "      <td>52</td>\n",
              "      <td>2</td>\n",
              "      <td>183</td>\n",
              "      <td>105.0</td>\n",
              "      <td>180</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>31.353579</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>99998</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>72.0</td>\n",
              "      <td>135</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>27.099251</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>99999</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>170</td>\n",
              "      <td>72.0</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24.913495</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68736 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-497ffb19-2565-4984-b8cf-3e7d066dacd0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-497ffb19-2565-4984-b8cf-3e7d066dacd0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-497ffb19-2565-4984-b8cf-3e7d066dacd0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25c26146-5145-440b-9366-a31996c10916\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25c26146-5145-440b-9366-a31996c10916')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25c26146-5145-440b-9366-a31996c10916 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_455da7fb-2c5e-4134-ae1a-4f878086185f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_455da7fb-2c5e-4134-ae1a-4f878086185f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 68736,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28845,\n        \"min\": 0,\n        \"max\": 99999,\n        \"num_unique_values\": 68736,\n        \"samples\": [\n          16257,\n          19941,\n          37136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 29,\n        \"max\": 64,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          39,\n          41,\n          40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 104,\n        \"max\": 207,\n        \"num_unique_values\": 83,\n        \"samples\": [\n          167,\n          168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.304111389682646,\n        \"min\": 31.0,\n        \"max\": 200.0,\n        \"num_unique_values\": 273,\n        \"samples\": [\n          50.0,\n          128.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap_hi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 60,\n        \"max\": 240,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          107,\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ap_lo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 40,\n        \"max\": 190,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          111,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoke\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alco\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"active\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cardio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.341967696971008,\n        \"min\": 10.726643598615919,\n        \"max\": 152.55177514792896,\n        \"num_unique_values\": 3744,\n        \"samples\": [\n          48.21996511747205,\n          19.05197378448407\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cholesterol_2\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cholesterol_3\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gluc_2\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gluc_3\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 로지스틱 회귀 모델링"
      ],
      "metadata": {
        "id": "cotHkOHB5Y7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#필요 라이브러리 이미 불러옴\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "3yC_GNU24-i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6IG6iCRWrNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#타켓 변수 y, 입력 변수 x 분리\n",
        "\n",
        "X = df.drop('cardio', axis=1)\n",
        "y = df['cardio']"
      ],
      "metadata": {
        "id": "uZxNG1At5b5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 데이터와 테스트용 데이터 분리"
      ],
      "metadata": {
        "id": "WiUOUAOG5u5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "3HWDFKmj5oF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#스케일링 -> 정규화: StandardScaler는 변수들을 평균 0, 표준편차 1로 바꾸어 학습 안정성 높임.\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Ve5vIUiv5yxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#로지스틱 회귀 모델 학습'\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Zj_0512y53Yp",
        "outputId": "fd20ae28-2fd2-405f-aa5e-0b6007d4556a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#예측 및 성능 평가\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "artxwm_X57wD",
        "outputId": "0a395e48-3762-4e23-a9fe-df5aca6ed964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.79      0.75      6944\n",
            "           1       0.76      0.67      0.71      6804\n",
            "\n",
            "    accuracy                           0.73     13748\n",
            "   macro avg       0.74      0.73      0.73     13748\n",
            "weighted avg       0.73      0.73      0.73     13748\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아무 처리 안 한 로지스틱 회귀모델의 정확도는 0.76(1기준으로 봄)"
      ],
      "metadata": {
        "id": "f0cr1OXi7rzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#중요 특성 확인\n",
        "feature_names = X.columns\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "# 중요 변수 정렬해서 보기\n",
        "importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients\n",
        "}).sort_values(by='Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(\"\\n중요한 피처 상위 10개:\")\n",
        "print(importance.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07BqYVaN6C8A",
        "outputId": "1701a5d4-ed6f-4565-f4a7-7d5dfc000c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "중요한 피처 상위 10개:\n",
            "          Feature  Coefficient\n",
            "5           ap_hi     0.885378\n",
            "12  cholesterol_3     0.346489\n",
            "1             age     0.340799\n",
            "4          weight     0.220333\n",
            "6           ap_lo     0.166830\n",
            "11  cholesterol_2     0.131896\n",
            "14         gluc_3    -0.095090\n",
            "9          active    -0.087511\n",
            "3          height    -0.072837\n",
            "10            BMI    -0.066073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "심혈관 질환 발병에 가장 큰 영향을 주는 변수는 ap_hi(수축기 혈압), 콜레스테롤이 매우 높은 경우, 나이 였음."
      ],
      "metadata": {
        "id": "0s5lYKYu7EUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤 포레스트 모델링"
      ],
      "metadata": {
        "id": "30L0_w3t_Qcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier"
      ],
      "metadata": {
        "id": "duzgDxKI_YPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. 특성/타겟 지정\n",
        "X = df.drop(['id', 'cardio'], axis=1)\n",
        "y = df['cardio']\n",
        "\n",
        "# 3. 학습/테스트 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "T8hzKFrv_Z1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=3, scoring='accuracy')\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Random Forest 최적 파라미터:\", rf_grid.best_params_)\n",
        "rf_pred = rf_grid.predict(X_test)\n",
        "print(\"정확도:\", accuracy_score(y_test, rf_pred))\n",
        "print(\"분류 리포트:\\n\", classification_report(y_test, rf_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcM-T1V1_f1h",
        "outputId": "46fa59ba-4e54-4a9b-ea57-84b098996d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest 최적 파라미터: {'class_weight': 'balanced', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "정확도: 0.7394285714285714\n",
            "분류 리포트:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.79      0.75      6988\n",
            "           1       0.77      0.69      0.73      7012\n",
            "\n",
            "    accuracy                           0.74     14000\n",
            "   macro avg       0.74      0.74      0.74     14000\n",
            "weighted avg       0.74      0.74      0.74     14000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XG boost 모델링"
      ],
      "metadata": {
        "id": "88IIMtwR_x3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5, 10],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "xgb_grid = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "                        xgb_params, cv=3, scoring='accuracy')\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"XGBoost 최적 파라미터:\", xgb_grid.best_params_)\n",
        "xgb_pred = xgb_grid.predict(X_test)\n",
        "print(\"정확도:\", accuracy_score(y_test, xgb_pred))\n",
        "print(\"분류 리포트:\\n\", classification_report(y_test, xgb_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8butfNK_h6p",
        "outputId": "50ba3f0d-8737-4a95-d0fc-da7e663b1423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:32:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:33:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost 최적 파라미터: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
            "정확도: 0.7387857142857143\n",
            "분류 리포트:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.77      0.75      6988\n",
            "           1       0.76      0.70      0.73      7012\n",
            "\n",
            "    accuracy                           0.74     14000\n",
            "   macro avg       0.74      0.74      0.74     14000\n",
            "weighted avg       0.74      0.74      0.74     14000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# light gbm 모델링"
      ],
      "metadata": {
        "id": "hGbeAtxo_4IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [-1, 10, 20],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'num_leaves': [31, 50],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "lgbm_grid = GridSearchCV(LGBMClassifier(random_state=42), lgbm_params, cv=3, scoring='accuracy')\n",
        "lgbm_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"LightGBM 최적 파라미터:\", lgbm_grid.best_params_)\n",
        "lgbm_pred = lgbm_grid.predict(X_test)\n",
        "print(\"정확도:\", accuracy_score(y_test, lgbm_pred))\n",
        "print(\"분류 리포트:\\n\", classification_report(y_test, lgbm_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCHzeQru_j5i",
        "outputId": "44f7c733-3948-49ac-edda-6cb3accebdd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004875 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004471 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004468 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004525 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008302 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004500 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004449 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004294 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010819 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011081 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006857 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004472 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004501 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004412 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011956 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006482 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011722 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006331 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006458 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006386 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006406 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006470 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007575 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004519 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004443 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004673 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007363 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007270 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006303 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006443 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006699 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005022 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004440 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004637 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004540 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006328 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006124 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006240 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007557 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004301 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004375 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004509 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006739 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006790 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006405 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004833 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004492 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004522 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004414 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004492 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004753 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004371 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004803 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004432 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004447 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005462 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006734 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004531 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004581 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004478 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007263 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007297 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004449 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004559 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012644 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006488 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004441 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004478 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004834 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007450 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004729 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007874 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004582 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007263 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007709 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004332 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004409 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007230 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006737 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006071 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004455 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004493 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004497 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004400 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004625 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004636 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004425 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004505 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004385 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004448 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008825 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007053 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010731 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010119 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004484 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004401 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006612 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004460 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005164 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031347 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067295 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006394 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005411 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004552 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004617 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007199 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004681 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007889 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004501 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007453 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004550 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004658 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006197 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006352 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006230 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009873 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004419 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004430 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004962 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004509 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007292 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004466 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007300 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019364 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004374 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004441 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006252 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 908\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 909\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 911\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 27216, number of negative: 27772\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006560 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 948\n",
            "[LightGBM] [Info] Number of data points in the train set: 54988, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494944 -> initscore=-0.020223\n",
            "[LightGBM] [Info] Start training from score -0.020223\n",
            "LightGBM 최적 파라미터: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.8}\n",
            "정확도: 0.7380709921443119\n",
            "분류 리포트:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.78      0.75      6944\n",
            "           1       0.75      0.70      0.72      6804\n",
            "\n",
            "    accuracy                           0.74     13748\n",
            "   macro avg       0.74      0.74      0.74     13748\n",
            "weighted avg       0.74      0.74      0.74     13748\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤서치, 앙상블"
      ],
      "metadata": {
        "id": "SWzvKQgPEV9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rV1_k0Q6EVHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 포레스트 튜닝\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "rf_random = RandomizedSearchCV(RandomForestClassifier(random_state=42),\n",
        "                               rf_params, n_iter=30, cv=3, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "rf_random.fit(X_train, y_train)\n",
        "rf_best = rf_random.best_estimator_\n",
        "\n",
        "# XGBoost 튜닝\n",
        "xgb_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "xgb_random = RandomizedSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "                                xgb_params, n_iter=30, cv=3, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "xgb_random.fit(X_train, y_train)\n",
        "xgb_best = xgb_random.best_estimator_\n",
        "\n",
        "# LightGBM 튜닝\n",
        "lgbm_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [-1, 10, 20],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'num_leaves': [31, 50, 70]\n",
        "}\n",
        "lgbm_random = RandomizedSearchCV(LGBMClassifier(random_state=42),\n",
        "                                 lgbm_params, n_iter=30, cv=3, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "lgbm_random.fit(X_train, y_train)\n",
        "lgbm_best = lgbm_random.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "BgotdfBvEck-",
        "outputId": "246281a5-312a-4da2-e4b8-b65572b13a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-7e0980c56f38>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m rf_random = RandomizedSearchCV(RandomForestClassifier(random_state=42),\n\u001b[1;32m      9\u001b[0m                                rf_params, n_iter=30, cv=3, scoring='accuracy', random_state=42, n_jobs=-1)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mrf_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2069\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2071\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m                 ):\n\u001b[0;32m-> 1799\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', rf_best),\n",
        "        ('xgb', xgb_best),\n",
        "        ('lgbm', lgbm_best)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6FLmsxZ5EdMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 예측\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "y_proba = voting_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 평가 지표\n",
        "print(\"정확도:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1-score:\", classification_report(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"혼동 행렬:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# ROC 곡선\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "plt.plot(fpr, tpr, label='VotingClassifier')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ek8l1Ej2EgF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 딥러닝 mlp"
      ],
      "metadata": {
        "id": "D07gsk_KJMpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서플로우 기반"
      ],
      "metadata": {
        "id": "1m5sGzQyJl7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UvKWPwkJpOm",
        "outputId": "d002cd71-1731-4da3-c1cf-47ae323ba55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# 1. 스케일링 (한 번 더 확인)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 2. 모델 정의\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(2, activation='softmax')  # 이진분류일 때 softmax(2) or sigmoid(1)\n",
        "])\n",
        "\n",
        "# 3. 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',  # y가 정수일 경우 sparse 사용\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. 학습\n",
        "history = model.fit(X_train_scaled, y_train, epochs=30, batch_size=64,\n",
        "                    validation_split=0.2, verbose=1)\n",
        "\n",
        "# 5. 예측\n",
        "y_pred_prob = model.predict(X_test_scaled)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# 6. 평가 지표\n",
        "print(\"정확도:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_prob[:, 1]))\n",
        "print(\"classification report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"혼동행렬:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq6gY_sBJsY-",
        "outputId": "2978281c-ac8a-45f3-dc8f-9aececaa7ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.6362 - loss: 0.6411 - val_accuracy: 0.7133 - val_loss: 0.5788\n",
            "Epoch 2/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7004 - loss: 0.5969 - val_accuracy: 0.7295 - val_loss: 0.5582\n",
            "Epoch 3/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7201 - loss: 0.5658 - val_accuracy: 0.7335 - val_loss: 0.5495\n",
            "Epoch 4/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7225 - loss: 0.5670 - val_accuracy: 0.7346 - val_loss: 0.5472\n",
            "Epoch 5/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7242 - loss: 0.5587 - val_accuracy: 0.7341 - val_loss: 0.5455\n",
            "Epoch 6/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.5534 - val_accuracy: 0.7369 - val_loss: 0.5418\n",
            "Epoch 7/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7296 - loss: 0.5492 - val_accuracy: 0.7350 - val_loss: 0.5450\n",
            "Epoch 8/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7295 - loss: 0.5531 - val_accuracy: 0.7357 - val_loss: 0.5404\n",
            "Epoch 9/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.5494 - val_accuracy: 0.7354 - val_loss: 0.5417\n",
            "Epoch 10/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5462 - val_accuracy: 0.7368 - val_loss: 0.5415\n",
            "Epoch 11/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5450 - val_accuracy: 0.7379 - val_loss: 0.5420\n",
            "Epoch 12/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.5467 - val_accuracy: 0.7367 - val_loss: 0.5405\n",
            "Epoch 13/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7318 - loss: 0.5460 - val_accuracy: 0.7366 - val_loss: 0.5428\n",
            "Epoch 14/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5444 - val_accuracy: 0.7355 - val_loss: 0.5407\n",
            "Epoch 15/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.5474 - val_accuracy: 0.7351 - val_loss: 0.5416\n",
            "Epoch 16/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.5487 - val_accuracy: 0.7380 - val_loss: 0.5402\n",
            "Epoch 17/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5433 - val_accuracy: 0.7367 - val_loss: 0.5414\n",
            "Epoch 18/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7307 - loss: 0.5479 - val_accuracy: 0.7381 - val_loss: 0.5403\n",
            "Epoch 19/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.5451 - val_accuracy: 0.7370 - val_loss: 0.5414\n",
            "Epoch 20/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5444 - val_accuracy: 0.7346 - val_loss: 0.5404\n",
            "Epoch 21/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5474 - val_accuracy: 0.7374 - val_loss: 0.5402\n",
            "Epoch 22/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: 0.5479 - val_accuracy: 0.7369 - val_loss: 0.5406\n",
            "Epoch 23/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.5444 - val_accuracy: 0.7363 - val_loss: 0.5413\n",
            "Epoch 24/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7326 - loss: 0.5449 - val_accuracy: 0.7350 - val_loss: 0.5418\n",
            "Epoch 25/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.5439 - val_accuracy: 0.7387 - val_loss: 0.5398\n",
            "Epoch 26/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5443 - val_accuracy: 0.7368 - val_loss: 0.5400\n",
            "Epoch 27/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.5494 - val_accuracy: 0.7371 - val_loss: 0.5409\n",
            "Epoch 28/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7355 - loss: 0.5410 - val_accuracy: 0.7371 - val_loss: 0.5407\n",
            "Epoch 29/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5425 - val_accuracy: 0.7396 - val_loss: 0.5393\n",
            "Epoch 30/30\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.5469 - val_accuracy: 0.7377 - val_loss: 0.5402\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "정확도: 0.7395714285714285\n",
            "F1-score: 0.7280727923627685\n",
            "ROC AUC: 0.8011070991718833\n",
            "classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.78      0.75      6988\n",
            "           1       0.76      0.70      0.73      7012\n",
            "\n",
            "    accuracy                           0.74     14000\n",
            "   macro avg       0.74      0.74      0.74     14000\n",
            "weighted avg       0.74      0.74      0.74     14000\n",
            "\n",
            "혼동행렬:\n",
            " [[5473 1515]\n",
            " [2131 4881]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_ckpt = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stop, model_ckpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9nTnwMZJ15c",
        "outputId": "ab2e7db0-07f8-4ea1-c59f-fdad9370f49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7353 - loss: 0.5438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7353 - loss: 0.5438 - val_accuracy: 0.7366 - val_loss: 0.5398\n",
            "Epoch 2/100\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5416 - val_accuracy: 0.7358 - val_loss: 0.5412\n",
            "Epoch 3/100\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5460 - val_accuracy: 0.7362 - val_loss: 0.5405\n",
            "Epoch 4/100\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.5457 - val_accuracy: 0.7352 - val_loss: 0.5417\n",
            "Epoch 5/100\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7303 - loss: 0.5468 - val_accuracy: 0.7357 - val_loss: 0.5411\n",
            "Epoch 6/100\n",
            "\u001b[1m700/700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7376 - loss: 0.5394 - val_accuracy: 0.7376 - val_loss: 0.5412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. 저장된 최적 모델 불러오기\n",
        "best_model = load_model('best_model.h5')\n",
        "\n",
        "# 2. 테스트 데이터로 예측\n",
        "y_pred_prob = best_model.predict(X_test_scaled)\n",
        "y_pred = y_pred_prob.argmax(axis=1)\n",
        "\n",
        "# 3. 정확도 출력\n",
        "print(\"✅ 정확도:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN1lYF7HKs4S",
        "outputId": "a8ad3802-f9e9-4b91-8241-e1a5925f0a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "✅ 정확도: 0.7412857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TabNet 기반 전이학습"
      ],
      "metadata": {
        "id": "cr9a7yu3OE6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "8HDq7v8oQ4S5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvTHLogzQiVv",
        "outputId": "45da5963-8d11-48cd-d66e-832e7eaa1fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tabnet\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 전체 경로 지정\n",
        "csv_path = os.path.join(path, \"cardio_train.csv\")\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv(csv_path, sep=';')\n",
        "print(df.head())\n",
        "\n",
        "# 필요한 전처리 예시 (본인 상황에 맞게 조절)\n",
        "df = df.drop(columns=[\"id\"])\n",
        "df[\"age\"] = df[\"age\"] / 365  # 나이를 일수에서 년으로 변환\n",
        "\n",
        "# 특성과 라벨 분리\n",
        "X = df.drop(\"cardio\", axis=1)\n",
        "y = df[\"cardio\"]\n",
        "\n",
        "# 인코딩\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# 훈련/검증용 분리\n",
        "prev_X_train, prev_X_test, prev_y_train, prev_y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuV6GZUUQb7I",
        "outputId": "8b85a08d-340f-49e9-8765-dcab5b5c4567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
            "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
            "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
            "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
            "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
            "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
            "\n",
            "   alco  active  cardio  \n",
            "0     0       1       0  \n",
            "1     0       1       1  \n",
            "2     0       0       1  \n",
            "3     0       1       1  \n",
            "4     0       0       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import numpy as np\n",
        "\n",
        "clf_pretrain = TabNetClassifier()\n",
        "\n",
        "clf_pretrain.fit(\n",
        "    X_train=prev_X_train.values,\n",
        "    y_train=prev_y_train,\n",
        "    eval_set=[(prev_X_test.values, prev_y_test)],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=20,\n",
        "    patience=5,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# 모델 저장\n",
        "clf_pretrain.save_model(\"pretrained_tabnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "2SAgHF9AQk5O",
        "outputId": "7f8944ca-2db3-4ae5-fdbd-eca6813dfb94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.62293 | val_0_accuracy: 0.501   |  0:00:04s\n",
            "epoch 1  | loss: 0.56774 | val_0_accuracy: 0.50414 |  0:00:07s\n",
            "epoch 2  | loss: 0.56021 | val_0_accuracy: 0.56564 |  0:00:10s\n",
            "epoch 3  | loss: 0.55765 | val_0_accuracy: 0.58207 |  0:00:19s\n",
            "epoch 4  | loss: 0.55447 | val_0_accuracy: 0.68814 |  0:00:24s\n",
            "epoch 5  | loss: 0.55254 | val_0_accuracy: 0.69686 |  0:00:27s\n",
            "epoch 6  | loss: 0.55233 | val_0_accuracy: 0.70064 |  0:00:33s\n",
            "epoch 7  | loss: 0.55057 | val_0_accuracy: 0.69114 |  0:00:36s\n",
            "epoch 8  | loss: 0.55037 | val_0_accuracy: 0.70607 |  0:00:39s\n",
            "epoch 9  | loss: 0.55332 | val_0_accuracy: 0.68529 |  0:00:43s\n",
            "epoch 10 | loss: 0.55377 | val_0_accuracy: 0.675   |  0:00:47s\n",
            "epoch 11 | loss: 0.55048 | val_0_accuracy: 0.682   |  0:00:50s\n",
            "epoch 12 | loss: 0.54914 | val_0_accuracy: 0.66929 |  0:00:54s\n",
            "epoch 13 | loss: 0.54853 | val_0_accuracy: 0.6825  |  0:00:57s\n",
            "\n",
            "Early stopping occurred at epoch 13 with best_epoch = 8 and best_val_0_accuracy = 0.70607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved model at pretrained_tabnet.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pretrained_tabnet.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dileep070/heart-disease-prediction-using-logistic-regression\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug79oecwOPmL",
        "outputId": "025728ae-a3d1-427e-ee2e-61d444874732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/heart-disease-prediction-using-logistic-regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 데이터 디렉토리 내 파일 리스트 확인\n",
        "files = os.listdir(path)\n",
        "print(\"Files in dataset folder:\", files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl74cnVtO7e7",
        "outputId": "b9011dfc-330b-4403-a868-eb1fdabf4907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in dataset folder: ['framingham.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib  # 모델 저장 및 불러오기"
      ],
      "metadata": {
        "id": "OZRoCiPhOQNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# framingham.csv 경로 설정\n",
        "csv_path = os.path.join(path, \"framingham.csv\")\n",
        "\n",
        "# 데이터 불러오기\n",
        "f_df = pd.read_csv(csv_path)\n",
        "\n",
        "# 첫 5행 미리 보기\n",
        "print(f_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qVBfhdJPTXD",
        "outputId": "252f4437-8c23-458c-89b3-9d89b3f143b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      male  age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
            "0        1   39        4.0              0         0.0     0.0   \n",
            "1        0   46        2.0              0         0.0     0.0   \n",
            "2        1   48        1.0              1        20.0     0.0   \n",
            "3        0   61        3.0              1        30.0     0.0   \n",
            "4        0   46        3.0              1        23.0     0.0   \n",
            "...    ...  ...        ...            ...         ...     ...   \n",
            "4233     1   50        1.0              1         1.0     0.0   \n",
            "4234     1   51        3.0              1        43.0     0.0   \n",
            "4235     0   48        2.0              1        20.0     NaN   \n",
            "4236     0   44        1.0              1        15.0     0.0   \n",
            "4237     0   52        2.0              0         0.0     0.0   \n",
            "\n",
            "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
            "0                   0             0         0    195.0  106.0   70.0  26.97   \n",
            "1                   0             0         0    250.0  121.0   81.0  28.73   \n",
            "2                   0             0         0    245.0  127.5   80.0  25.34   \n",
            "3                   0             1         0    225.0  150.0   95.0  28.58   \n",
            "4                   0             0         0    285.0  130.0   84.0  23.10   \n",
            "...               ...           ...       ...      ...    ...    ...    ...   \n",
            "4233                0             1         0    313.0  179.0   92.0  25.97   \n",
            "4234                0             0         0    207.0  126.5   80.0  19.71   \n",
            "4235                0             0         0    248.0  131.0   72.0  22.00   \n",
            "4236                0             0         0    210.0  126.5   87.0  19.16   \n",
            "4237                0             0         0    269.0  133.5   83.0  21.47   \n",
            "\n",
            "      heartRate  glucose  TenYearCHD  \n",
            "0          80.0     77.0           0  \n",
            "1          95.0     76.0           0  \n",
            "2          75.0     70.0           0  \n",
            "3          65.0    103.0           1  \n",
            "4          85.0     85.0           0  \n",
            "...         ...      ...         ...  \n",
            "4233       66.0     86.0           1  \n",
            "4234       65.0     68.0           0  \n",
            "4235       84.0     86.0           0  \n",
            "4236       86.0      NaN           0  \n",
            "4237       80.0    107.0           0  \n",
            "\n",
            "[4238 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 제거\n",
        "f_df.dropna(inplace=True)\n",
        "\n",
        "# 특성과 타겟 설정\n",
        "X = f_df.drop(columns=[\"TenYearCHD\"])\n",
        "y = f_df[\"TenYearCHD\"]\n",
        "\n",
        "# 데이터 분할\n",
        "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "qc4399rHOVtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 요약 정보\n",
        "print(f_df.info())\n",
        "\n",
        "# 결측값 확인\n",
        "print(f_df.isnull().sum())\n",
        "\n",
        "# 통계 요약\n",
        "print(f_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jamMNQaNPYpc",
        "outputId": "437bf0ce-f4b6-48a6-b83c-96c07d2e85e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3656 entries, 0 to 4237\n",
            "Data columns (total 16 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   male             3656 non-null   int64  \n",
            " 1   age              3656 non-null   int64  \n",
            " 2   education        3656 non-null   float64\n",
            " 3   currentSmoker    3656 non-null   int64  \n",
            " 4   cigsPerDay       3656 non-null   float64\n",
            " 5   BPMeds           3656 non-null   float64\n",
            " 6   prevalentStroke  3656 non-null   int64  \n",
            " 7   prevalentHyp     3656 non-null   int64  \n",
            " 8   diabetes         3656 non-null   int64  \n",
            " 9   totChol          3656 non-null   float64\n",
            " 10  sysBP            3656 non-null   float64\n",
            " 11  diaBP            3656 non-null   float64\n",
            " 12  BMI              3656 non-null   float64\n",
            " 13  heartRate        3656 non-null   float64\n",
            " 14  glucose          3656 non-null   float64\n",
            " 15  TenYearCHD       3656 non-null   int64  \n",
            "dtypes: float64(9), int64(7)\n",
            "memory usage: 485.6 KB\n",
            "None\n",
            "male               0\n",
            "age                0\n",
            "education          0\n",
            "currentSmoker      0\n",
            "cigsPerDay         0\n",
            "BPMeds             0\n",
            "prevalentStroke    0\n",
            "prevalentHyp       0\n",
            "diabetes           0\n",
            "totChol            0\n",
            "sysBP              0\n",
            "diaBP              0\n",
            "BMI                0\n",
            "heartRate          0\n",
            "glucose            0\n",
            "TenYearCHD         0\n",
            "dtype: int64\n",
            "              male          age    education  currentSmoker   cigsPerDay  \\\n",
            "count  3656.000000  3656.000000  3656.000000    3656.000000  3656.000000   \n",
            "mean      0.443654    49.557440     1.979759       0.489059     9.022155   \n",
            "std       0.496883     8.561133     1.022657       0.499949    11.918869   \n",
            "min       0.000000    32.000000     1.000000       0.000000     0.000000   \n",
            "25%       0.000000    42.000000     1.000000       0.000000     0.000000   \n",
            "50%       0.000000    49.000000     2.000000       0.000000     0.000000   \n",
            "75%       1.000000    56.000000     3.000000       1.000000    20.000000   \n",
            "max       1.000000    70.000000     4.000000       1.000000    70.000000   \n",
            "\n",
            "            BPMeds  prevalentStroke  prevalentHyp     diabetes      totChol  \\\n",
            "count  3656.000000      3656.000000   3656.000000  3656.000000  3656.000000   \n",
            "mean      0.030361         0.005744      0.311543     0.027079   236.873085   \n",
            "std       0.171602         0.075581      0.463187     0.162335    44.096223   \n",
            "min       0.000000         0.000000      0.000000     0.000000   113.000000   \n",
            "25%       0.000000         0.000000      0.000000     0.000000   206.000000   \n",
            "50%       0.000000         0.000000      0.000000     0.000000   234.000000   \n",
            "75%       0.000000         0.000000      1.000000     0.000000   263.250000   \n",
            "max       1.000000         1.000000      1.000000     1.000000   600.000000   \n",
            "\n",
            "             sysBP        diaBP          BMI    heartRate      glucose  \\\n",
            "count  3656.000000  3656.000000  3656.000000  3656.000000  3656.000000   \n",
            "mean    132.368025    82.912062    25.784185    75.730580    81.856127   \n",
            "std      22.092444    11.974825     4.065913    11.982952    23.910128   \n",
            "min      83.500000    48.000000    15.540000    44.000000    40.000000   \n",
            "25%     117.000000    75.000000    23.080000    68.000000    71.000000   \n",
            "50%     128.000000    82.000000    25.380000    75.000000    78.000000   \n",
            "75%     144.000000    90.000000    28.040000    82.000000    87.000000   \n",
            "max     295.000000   142.500000    56.800000   143.000000   394.000000   \n",
            "\n",
            "        TenYearCHD  \n",
            "count  3656.000000  \n",
            "mean      0.152352  \n",
            "std       0.359411  \n",
            "min       0.000000  \n",
            "25%       0.000000  \n",
            "50%       0.000000  \n",
            "75%       0.000000  \n",
            "max       1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 타깃 분포 확인\n",
        "print(f_df['TenYearCHD'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKTffUNcPbrv",
        "outputId": "7a3c110d-658f-4c41-b74d-20499d6767aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TenYearCHD\n",
            "0    3099\n",
            "1     557\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 새로운 모델 객체 생성\n",
        "clf_finetune = TabNetClassifier()\n",
        "\n",
        "# 2. 저장된 모델 불러오기 (.zip 포함!)\n",
        "clf_finetune.load_model(\"pretrained_tabnet.zip\")\n",
        "\n",
        "# 3. 새로운 데이터로 fine-tuning\n",
        "clf_finetune.fit(\n",
        "    X_train=new_X_train.values,\n",
        "    y_train=new_y_train,\n",
        "    eval_set=[(new_X_test.values, new_y_test)],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=10,\n",
        "    patience=3,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXt0QQy5PoiJ",
        "outputId": "e773dd92-7400-4dce-f812-2f17030c9fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.7653  | val_0_accuracy: 0.55328 |  0:00:00s\n",
            "epoch 1  | loss: 0.55639 | val_0_accuracy: 0.47131 |  0:00:00s\n",
            "epoch 2  | loss: 0.50056 | val_0_accuracy: 0.6612  |  0:00:00s\n",
            "epoch 3  | loss: 0.44687 | val_0_accuracy: 0.72951 |  0:00:00s\n",
            "epoch 4  | loss: 0.44419 | val_0_accuracy: 0.56011 |  0:00:00s\n",
            "epoch 5  | loss: 0.43526 | val_0_accuracy: 0.62432 |  0:00:00s\n",
            "epoch 6  | loss: 0.4117  | val_0_accuracy: 0.34426 |  0:00:00s\n",
            "\n",
            "Early stopping occurred at epoch 6 with best_epoch = 3 and best_val_0_accuracy = 0.72951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_finetune.save_model(\"tabnet_finetuned_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "--2-9RAPPvss",
        "outputId": "3c1e5ec5-16de-4c4a-a18f-b2873d2ff4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved model at tabnet_finetuned_model.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tabnet_finetuned_model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# 예측 수행\n",
        "y_pred = clf_finetune.predict(new_X_test.values)\n",
        "\n",
        "# 정확도 확인\n",
        "print(\"정확도:\", accuracy_score(new_y_test, y_pred))\n",
        "\n",
        "# 분류 리포트\n",
        "print(\"분류 리포트:\\n\", classification_report(new_y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3qjcHUaTCU6",
        "outputId": "50840bec-6b1a-469c-d010-49e46fab8905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7295081967213115\n",
            "분류 리포트:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.84       620\n",
            "           1       0.14      0.15      0.15       112\n",
            "\n",
            "    accuracy                           0.73       732\n",
            "   macro avg       0.49      0.49      0.49       732\n",
            "weighted avg       0.74      0.73      0.73       732\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "R7AsHFpITx46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# smote"
      ],
      "metadata": {
        "id": "ro3LqzJdTeGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SPE9wCnTSYx",
        "outputId": "f4de1d1d-545e-42f7-9556-cfa37b7bfe99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# SMOTE 인스턴스 생성\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# 학습 데이터에 적용\n",
        "X_train_smote, y_train_smote = smote.fit_resample(new_X_train, new_y_train)\n",
        "\n",
        "# 결과 확인\n",
        "print(\"SMOTE 전:\", dict(pd.Series(new_y_train).value_counts()))\n",
        "print(\"SMOTE 후:\", dict(pd.Series(y_train_smote).value_counts()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA9gqpeEThTN",
        "outputId": "dfc2657f-c6f0-404d-c66f-f427824f3979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE 전: {0: np.int64(2479), 1: np.int64(445)}\n",
            "SMOTE 후: {0: np.int64(2479), 1: np.int64(2479)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SMOTE 데이터로 전이학습 모델 fine-tuning"
      ],
      "metadata": {
        "id": "uOeHLe46Tqky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_finetune = TabNetClassifier()\n",
        "clf_finetune.load_model(\"pretrained_tabnet.zip\")\n",
        "\n",
        "clf_finetune.fit(\n",
        "    X_train=X_train_smote.values,\n",
        "    y_train=y_train_smote,\n",
        "    eval_set=[(new_X_test.values, new_y_test)],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=20,\n",
        "    patience=5,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk5d-DqtTj6Z",
        "outputId": "fc4b9040-a65d-4059-9c91-ec412e02763b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.77011 | val_0_accuracy: 0.21448 |  0:00:00s\n",
            "epoch 1  | loss: 0.65164 | val_0_accuracy: 0.1612  |  0:00:01s\n",
            "epoch 2  | loss: 0.64237 | val_0_accuracy: 0.21858 |  0:00:02s\n",
            "epoch 3  | loss: 0.63285 | val_0_accuracy: 0.20628 |  0:00:02s\n",
            "epoch 4  | loss: 0.61273 | val_0_accuracy: 0.47131 |  0:00:03s\n",
            "epoch 5  | loss: 0.61374 | val_0_accuracy: 0.53825 |  0:00:03s\n",
            "epoch 6  | loss: 0.6073  | val_0_accuracy: 0.5765  |  0:00:04s\n",
            "epoch 7  | loss: 0.60246 | val_0_accuracy: 0.60656 |  0:00:05s\n",
            "epoch 8  | loss: 0.59822 | val_0_accuracy: 0.54372 |  0:00:05s\n",
            "epoch 9  | loss: 0.60011 | val_0_accuracy: 0.47268 |  0:00:06s\n",
            "epoch 10 | loss: 0.59932 | val_0_accuracy: 0.4153  |  0:00:06s\n",
            "epoch 11 | loss: 0.59308 | val_0_accuracy: 0.36339 |  0:00:07s\n",
            "epoch 12 | loss: 0.59041 | val_0_accuracy: 0.32514 |  0:00:08s\n",
            "\n",
            "Early stopping occurred at epoch 12 with best_epoch = 7 and best_val_0_accuracy = 0.60656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 수행\n",
        "y_pred = clf_finetune.predict(new_X_test.values)\n",
        "\n",
        "# 정확도 확인\n",
        "print(\"정확도:\", accuracy_score(new_y_test, y_pred))\n",
        "\n",
        "# 분류 리포트\n",
        "print(\"분류 리포트:\\n\", classification_report(new_y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTd7k7IvToWo",
        "outputId": "8cf1f384-70e0-4bd9-d777-c67bf2fe65b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.6065573770491803\n",
            "분류 리포트:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.64      0.73       620\n",
            "           1       0.18      0.43      0.25       112\n",
            "\n",
            "    accuracy                           0.61       732\n",
            "   macro avg       0.52      0.53      0.49       732\n",
            "weighted avg       0.76      0.61      0.66       732\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recall 상승 → 질병 환자를 더 잘 찾아냄 (SMOTE가 의도한 방향)"
      ],
      "metadata": {
        "id": "XxVeiE_2UWuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#개선 사항: 전이학습 fine-tuning 시 더 오랜 학습이나 작은 learning rate가 필요할 수 있음, 정확도 대신 AUC-ROC나 PR Curve를 사용"
      ],
      "metadata": {
        "id": "4rUDbsHBUf6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "# TabNetClassifier 객체 생성 시 learning_rate 설정 필요\n",
        "clf_finetune = TabNetClassifier(\n",
        "     optimizer_params=dict(lr=1e-3),\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# 전이학습 모델 로드\n",
        "clf_finetune.load_model(\"pretrained_tabnet.zip\")\n",
        "\n",
        "# fine-tuning 진행\n",
        "clf_finetune.fit(\n",
        "    X_train=X_train_smote.values,\n",
        "    y_train=y_train_smote,\n",
        "    eval_set=[(new_X_test.values, new_y_test)],\n",
        "    max_epochs=10,\n",
        "    patience=10,\n",
        "    batch_size=512,\n",
        "    virtual_batch_size=128,\n",
        "    eval_metric=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sxw8P0BUc1j",
        "outputId": "8ae85675-e912-42ed-87d1-dbb129a6738c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.71493 | val_0_accuracy: 0.25273 |  0:00:01s\n",
            "epoch 1  | loss: 0.64395 | val_0_accuracy: 0.19262 |  0:00:01s\n",
            "epoch 2  | loss: 0.62351 | val_0_accuracy: 0.35246 |  0:00:02s\n",
            "epoch 3  | loss: 0.61055 | val_0_accuracy: 0.39617 |  0:00:03s\n",
            "epoch 4  | loss: 0.60882 | val_0_accuracy: 0.36885 |  0:00:03s\n",
            "epoch 5  | loss: 0.60616 | val_0_accuracy: 0.49454 |  0:00:04s\n",
            "epoch 6  | loss: 0.5972  | val_0_accuracy: 0.22678 |  0:00:04s\n",
            "epoch 7  | loss: 0.5984  | val_0_accuracy: 0.20765 |  0:00:04s\n",
            "epoch 8  | loss: 0.58867 | val_0_accuracy: 0.19262 |  0:00:05s\n",
            "epoch 9  | loss: 0.58713 | val_0_accuracy: 0.15847 |  0:00:05s\n",
            "Stop training because you reached max_epochs = 10 with best_epoch = 5 and best_val_0_accuracy = 0.49454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 수행\n",
        "y_pred = clf_finetune.predict(new_X_test.values)\n",
        "\n",
        "# 정확도 확인\n",
        "print(\"정확도:\", accuracy_score(new_y_test, y_pred))\n",
        "\n",
        "# 분류 리포트\n",
        "print(\"분류 리포트:\\n\", classification_report(new_y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTidtkpyVHQV",
        "outputId": "72745ee5-aefc-4a69-dec0-369cca2c4d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.49453551912568305\n",
            "분류 리포트:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.48      0.62       620\n",
            "           1       0.16      0.55      0.25       112\n",
            "\n",
            "    accuracy                           0.49       732\n",
            "   macro avg       0.51      0.52      0.43       732\n",
            "weighted avg       0.75      0.49      0.56       732\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# **SMOTETomek이나 SMOTEENN**을 사용하여 노이즈 샘플 제거 병행 필요\n",
        "#max_epochs를 너무 많이 주면 모델이 기존 학습 내용을 과잉 덮어씀 (catastrophic forgetting)"
      ],
      "metadata": {
        "id": "Y31TOXXPVc0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전이학습 활용방안"
      ],
      "metadata": {
        "id": "Omb_Nm_aEQk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "목표: 인터랙티브 건강 예측 & 개선 가이드 시스템\n",
        "\n",
        "입력값을 통해 현재와 10년 후 심혈관 질환 발병 확률 예측\n",
        "\n",
        "발병 확률을 낮추기 위해 어떤 항목을 개선해야 하는지 제안\n",
        "\n",
        "구체적으로 얼마까지 수치를 낮춰야 하는지 목표값 제시\n",
        "\n",
        "코랩에서 작동 가능한 UI 또는 코드 구조"
      ],
      "metadata": {
        "id": "uisf-v2KforK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub pytorch-tabnet\n",
        "\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlHIihd_PHw6",
        "outputId": "03b8495b-2268-4578-a8e3-6f7557bfc8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.6.0+cu124)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 첫 번째 데이터셋 로드 및 전처리 (cardio_train.csv)\n",
        "path = kagglehub.dataset_download(\"sulianova/cardiovascular-disease-dataset\")\n",
        "csv_path = os.path.join(path, \"cardio_train.csv\")\n",
        "df = pd.read_csv(csv_path, sep=';')\n",
        "\n",
        "df['age'] = (df['age'] / 365).astype(int)\n",
        "df = df[(df['ap_hi'] > 50) & (df['ap_hi'] < 250)]\n",
        "df = df[(df['ap_lo'] > 30) & (df['ap_lo'] < 200)]\n",
        "df = df[(df['height'] > 100) & (df['height'] < 250)]\n",
        "df = df[(df['weight'] > 30) & (df['weight'] < 250)]\n",
        "\n",
        "df['BMI'] = df['weight'] / ((df['height'] / 100) ** 2)\n",
        "df = pd.get_dummies(df, columns=['cholesterol', 'gluc'], drop_first=True)\n",
        "\n",
        "X = df.drop(['cardio', 'id'], axis=1)\n",
        "y = df['cardio']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "wRnn2YFrPO9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 로지스틱 회귀 모델\n",
        "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 3. LightGBM 하이퍼파라미터 튜닝\n",
        "lgbm_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [-1, 10, 20],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'num_leaves': [31, 50],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "lgbm_grid = GridSearchCV(LGBMClassifier(random_state=42), lgbm_params, cv=3, scoring='accuracy')\n",
        "lgbm_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"LightGBM 최적 파라미터:\", lgbm_grid.best_params_)\n",
        "lgbm_pred = lgbm_grid.predict(X_test)\n",
        "print(\"정확도:\", accuracy_score(y_test, lgbm_pred))\n",
        "print(\"분류 리포트:\\n\", classification_report(y_test, lgbm_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2jwOf_ePQUI",
        "outputId": "956578ea-c74e-43bd-f1f8-848c4513ab84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006057 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006217 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006023 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004198 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004386 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004336 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004577 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007351 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004435 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004269 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004329 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004233 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004307 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004213 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005998 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012980 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004822 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004356 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004277 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004360 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006927 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006571 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004377 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004365 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004248 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004435 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004298 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004950 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004328 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004448 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006910 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004513 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004264 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005929 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005913 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005953 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004292 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004225 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004844 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004357 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007216 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006047 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005984 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006419 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005455 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004277 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004303 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004359 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004288 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004374 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006910 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005923 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007392 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004348 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004387 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006035 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004253 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006843 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004295 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004363 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006384 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006441 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006078 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004287 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004693 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005115 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004494 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006836 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004218 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004316 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007257 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004416 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004795 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004652 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004287 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005861 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005281 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006184 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004346 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004289 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004404 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004295 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004261 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004392 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004346 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004447 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005894 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004364 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004726 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005348 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004170 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006015 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005913 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008906 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006066 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004574 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005115 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004207 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007054 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004323 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004323 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004347 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004455 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004877 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004316 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010493 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010369 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005987 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004656 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004403 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004345 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004363 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004362 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004720 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004270 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004311 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006206 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004450 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007157 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004357 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004293 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006009 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005971 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005742 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005041 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18514\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006014 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 653\n",
            "[LightGBM] [Info] Number of data points in the train set: 36658, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494953 -> initscore=-0.020187\n",
            "[LightGBM] [Info] Start training from score -0.020187\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006297 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 654\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 18144, number of negative: 18515\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006220 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 656\n",
            "[LightGBM] [Info] Number of data points in the train set: 36659, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494940 -> initscore=-0.020241\n",
            "[LightGBM] [Info] Start training from score -0.020241\n",
            "[LightGBM] [Info] Number of positive: 27216, number of negative: 27772\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007943 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 693\n",
            "[LightGBM] [Info] Number of data points in the train set: 54988, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494944 -> initscore=-0.020223\n",
            "[LightGBM] [Info] Start training from score -0.020223\n",
            "LightGBM 최적 파라미터: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 31, 'subsample': 0.8}\n",
            "정확도: 0.7352342158859471\n",
            "분류 리포트:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.77      0.75      6944\n",
            "           1       0.75      0.69      0.72      6804\n",
            "\n",
            "    accuracy                           0.74     13748\n",
            "   macro avg       0.74      0.73      0.73     13748\n",
            "weighted avg       0.74      0.74      0.73     13748\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. TabNet 사전 학습 (cardio 데이터 사용)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Split\n",
        "prev_X_train, prev_X_test, prev_y_train, prev_y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 2: Label Encoding\n",
        "le = LabelEncoder()\n",
        "prev_y_train_encoded = le.fit_transform(prev_y_train)\n",
        "prev_y_test_encoded = le.transform(prev_y_test)\n",
        "\n",
        "# Step 3: Ensure input arrays are float32\n",
        "X_train_np = prev_X_train.values.astype(np.float32)\n",
        "X_test_np = prev_X_test.values.astype(np.float32)\n",
        "y_train_np = prev_y_train_encoded.astype(np.int64)\n",
        "y_test_np = prev_y_test_encoded.astype(np.int64)\n",
        "\n",
        "# Step 4: Fit TabNet\n",
        "clf_pretrain = TabNetClassifier()\n",
        "clf_pretrain.fit(\n",
        "    X_train=X_train_np,\n",
        "    y_train=y_train_np,\n",
        "    eval_set=[(X_test_np, y_test_np)],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=20,\n",
        "    patience=5,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# Step 5: 저장\n",
        "clf_pretrain.save_model(\"pretrained_tabnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "oxe7TDPGPS3m",
        "outputId": "800c1e83-46d4-4ce8-b2a2-4d32f7db9672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.59908 | val_0_accuracy: 0.49636 |  0:00:03s\n",
            "epoch 1  | loss: 0.56379 | val_0_accuracy: 0.50095 |  0:00:07s\n",
            "epoch 2  | loss: 0.56114 | val_0_accuracy: 0.51608 |  0:00:11s\n",
            "epoch 3  | loss: 0.55982 | val_0_accuracy: 0.57186 |  0:00:15s\n",
            "epoch 4  | loss: 0.55507 | val_0_accuracy: 0.65275 |  0:00:18s\n",
            "epoch 5  | loss: 0.55237 | val_0_accuracy: 0.70665 |  0:00:21s\n",
            "epoch 6  | loss: 0.55033 | val_0_accuracy: 0.71887 |  0:00:25s\n",
            "epoch 7  | loss: 0.54989 | val_0_accuracy: 0.72665 |  0:00:29s\n",
            "epoch 8  | loss: 0.55054 | val_0_accuracy: 0.72563 |  0:00:32s\n",
            "epoch 9  | loss: 0.54954 | val_0_accuracy: 0.72585 |  0:00:35s\n",
            "epoch 10 | loss: 0.54836 | val_0_accuracy: 0.72847 |  0:00:39s\n",
            "epoch 11 | loss: 0.55011 | val_0_accuracy: 0.72992 |  0:00:42s\n",
            "epoch 12 | loss: 0.55065 | val_0_accuracy: 0.72527 |  0:00:45s\n",
            "epoch 13 | loss: 0.54963 | val_0_accuracy: 0.7268  |  0:00:49s\n",
            "epoch 14 | loss: 0.54862 | val_0_accuracy: 0.73152 |  0:00:53s\n",
            "epoch 15 | loss: 0.54733 | val_0_accuracy: 0.73007 |  0:00:56s\n",
            "epoch 16 | loss: 0.54713 | val_0_accuracy: 0.73218 |  0:01:00s\n",
            "epoch 17 | loss: 0.54618 | val_0_accuracy: 0.73232 |  0:01:03s\n",
            "epoch 18 | loss: 0.54654 | val_0_accuracy: 0.73211 |  0:01:07s\n",
            "epoch 19 | loss: 0.54542 | val_0_accuracy: 0.7292  |  0:01:10s\n",
            "Stop training because you reached max_epochs = 20 with best_epoch = 17 and best_val_0_accuracy = 0.73232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved model at pretrained_tabnet.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pretrained_tabnet.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#예측 결과를 나중에 다시 문자로 보고 싶으면  le.inverse_transform(predictions)"
      ],
      "metadata": {
        "id": "-y_Q9pz_R598"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Framingham 데이터셋 로드 및 fine-tuning\n",
        "path = kagglehub.dataset_download(\"dileep070/heart-disease-prediction-using-logistic-regression\")\n",
        "csv_path = os.path.join(path, \"framingham.csv\")\n",
        "f_df = pd.read_csv(csv_path)\n",
        "f_df.dropna(inplace=True)\n",
        "\n",
        "new_X = f_df.drop(columns=[\"TenYearCHD\"])\n",
        "new_y = f_df[\"TenYearCHD\"]\n",
        "\n",
        "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(\n",
        "    new_X, new_y, test_size=0.2, random_state=42, stratify=new_y\n",
        ")"
      ],
      "metadata": {
        "id": "LQqO4LOhPVCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_finetune = TabNetClassifier()\n",
        "clf_finetune.load_model(\"pretrained_tabnet.zip\")\n",
        "clf_finetune.fit(\n",
        "    X_train=new_X_train.values,\n",
        "    y_train=new_y_train,\n",
        "    eval_set=[(new_X_test.values, new_y_test)],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=10,\n",
        "    patience=3,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O020y2wgPYr6",
        "outputId": "5f2e3288-7c23-4864-cb63-641bef01d6e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.7653  | val_0_accuracy: 0.55328 |  0:00:00s\n",
            "epoch 1  | loss: 0.55639 | val_0_accuracy: 0.47131 |  0:00:00s\n",
            "epoch 2  | loss: 0.50056 | val_0_accuracy: 0.6612  |  0:00:00s\n",
            "epoch 3  | loss: 0.44687 | val_0_accuracy: 0.72951 |  0:00:01s\n",
            "epoch 4  | loss: 0.44419 | val_0_accuracy: 0.56011 |  0:00:01s\n",
            "epoch 5  | loss: 0.43526 | val_0_accuracy: 0.62432 |  0:00:02s\n",
            "epoch 6  | loss: 0.4117  | val_0_accuracy: 0.34426 |  0:00:02s\n",
            "\n",
            "Early stopping occurred at epoch 6 with best_epoch = 3 and best_val_0_accuracy = 0.72951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 사용자 입력 기반 예측 인터페이스 정의\n",
        "out = widgets.Output()\n",
        "\n",
        "def predict_and_suggest(age, ap_hi, ap_lo, height, weight,\n",
        "                        cholesterol, gluc, smoke, alco, active, gender):\n",
        "    out.clear_output()\n",
        "\n",
        "    bmi = weight / ((height / 100) ** 2)\n",
        "\n",
        "    # 학습 시 사용한 컬럼명과 순서대로 딕셔너리 만들기\n",
        "    input_data = {\n",
        "        'age': age,\n",
        "        'gender': gender,\n",
        "        'height': height,\n",
        "        'weight': weight,\n",
        "        'ap_hi': ap_hi,\n",
        "        'ap_lo': ap_lo,\n",
        "        'smoke': smoke,\n",
        "        'alco': alco,\n",
        "        'active': active,\n",
        "        'BMI': bmi,\n",
        "        'cholesterol_2': 1 if cholesterol == 2 else 0,\n",
        "        'cholesterol_3': 1 if cholesterol == 3 else 0,\n",
        "        'gluc_2': 1 if gluc == 2 else 0,\n",
        "        'gluc_3': 1 if gluc == 3 else 0\n",
        "    }\n",
        "\n",
        "    # X.columns.tolist() : 학습 때 사용한 컬럼명과 순서 (14개여야 함)\n",
        "    feature_cols = X.columns.tolist()\n",
        "\n",
        "    # input_df 생성 및 컬럼 순서 맞추기\n",
        "    input_df = pd.DataFrame([input_data])[feature_cols]\n",
        "\n",
        "    # TabNet은 보통 스케일링 안 함 -> scaler.transform() 없이 원본 데이터 넣기\n",
        "    input_values = input_df.values\n",
        "\n",
        "    # 예측\n",
        "    prob = clf_finetune.predict_proba(input_values)[0][1]\n",
        "\n",
        "    suggestions = []\n",
        "    targets = {}\n",
        "\n",
        "    if ap_hi > 120:\n",
        "        suggestions.append(\"수축기 혈압 낮추기\")\n",
        "        targets['ap_hi'] = 120\n",
        "\n",
        "    if ap_lo > 80:\n",
        "        suggestions.append(\"이완기 혈압 낮추기\")\n",
        "        targets['ap_lo'] = 80\n",
        "\n",
        "    if bmi > 24.9:\n",
        "        suggestions.append(\"BMI 줄이기 (체중 감량)\")\n",
        "        targets['BMI'] = 24.9\n",
        "\n",
        "    if cholesterol > 1:\n",
        "        suggestions.append(\"콜레스테롤 개선\")\n",
        "        targets['cholesterol'] = 1\n",
        "\n",
        "    if gluc > 1:\n",
        "        suggestions.append(\"혈당 개선\")\n",
        "        targets['gluc'] = 1\n",
        "\n",
        "    if smoke == 1:\n",
        "        suggestions.append(\"금연\")\n",
        "\n",
        "    if alco == 1:\n",
        "        suggestions.append(\"음주 줄이기\")\n",
        "\n",
        "    if active == 0:\n",
        "        suggestions.append(\"운동량 늘리기\")\n",
        "\n",
        "    with out:\n",
        "        print(f\"예측된 심혈관 질환 발병 확률: {prob*100:.2f}%\")\n",
        "        if suggestions:\n",
        "            print(\"\\n개선이 권장되는 항목:\")\n",
        "            for s in suggestions:\n",
        "                print(\"-\", s)\n",
        "            print(\"\\n개선 목표값:\")\n",
        "            for k, v in targets.items():\n",
        "                print(f\"  {k} : {v}\")\n",
        "        else:\n",
        "            print(\"현재 위험 요인은 크게 없습니다. 꾸준히 건강 관리하세요!\")"
      ],
      "metadata": {
        "id": "Ogq7nmeUUGL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 입력용 위젯 설정\n",
        "age_slider = IntSlider(value=50, min=20, max=90, description='나이(년):')\n",
        "ap_hi_slider = IntSlider(value=120, min=70, max=200, description='수축기 혈압:')\n",
        "ap_lo_slider = IntSlider(value=80, min=40, max=120, description='이완기 혈압:')\n",
        "height_slider = IntSlider(value=170, min=140, max=210, description='키(cm):')\n",
        "weight_slider = FloatSlider(value=70, min=40, max=150, step=0.1, description='몸무게(kg):')\n",
        "\n",
        "cholesterol_dropdown = Dropdown(options=[1, 2, 3], value=1, description='콜레스테롤:')\n",
        "gluc_dropdown = Dropdown(options=[1, 2, 3], value=1, description='혈당:')\n",
        "smoke_dropdown = Dropdown(options=[0,1], value=0, description='흡연 여부:')\n",
        "alco_dropdown = Dropdown(options=[0,1], value=0, description='음주 여부:')\n",
        "active_dropdown = Dropdown(options=[0,1], value=1, description='활동 여부:')\n",
        "gender_dropdown = Dropdown(options=[1,2], value=1, description='성별(1:남, 2:여):')"
      ],
      "metadata": {
        "id": "_tCkl0yeOG5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시 실행\n",
        "predict_and_suggest(\n",
        "    age=50, ap_hi=130, ap_lo=90, height=165, weight=75,\n",
        "    cholesterol=2, gluc=1, smoke=0, alco=0, active=0, gender=1\n",
        ")\n",
        "display(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "Na9C3ht8PhrY",
        "outputId": "0c8fb482-7fdc-4773-929d-d11d0c5f3e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "running_mean should contain 14 elements not 15",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-177-00ec72f5cb3a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 예시 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m predict_and_suggest(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0map_hi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m130\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0map_lo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m165\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcholesterol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgluc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoke\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malco\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-175-45072bee5ef9>\u001b[0m in \u001b[0;36mpredict_and_suggest\u001b[0;34m(age, ap_hi, ap_lo, height, weight, cholesterol, gluc, smoke, alco, active, gender)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_finetune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/tab_model.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0msteps_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, prior)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2820\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2822\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2823\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2824\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 14 elements not 15"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_suggest(age, ap_hi, ap_lo, height, weight,\n",
        "                        cholesterol, gluc, smoke, alco, active, gender):\n",
        "    out.clear_output()\n",
        "    # 입력값 DataFrame 생성 및 전처리\n",
        "    input_df = pd.DataFrame({\n",
        "        'age': [age],\n",
        "        'ap_hi': [ap_hi],\n",
        "        'ap_lo': [ap_lo],\n",
        "        'height': [height],\n",
        "        'weight': [weight],\n",
        "        'cholesterol_2': [1 if cholesterol==2 else 0],\n",
        "        'cholesterol_3': [1 if cholesterol==3 else 0],\n",
        "        'gluc_2': [1 if gluc==2 else 0],\n",
        "        'gluc_3': [1 if gluc==3 else 0],\n",
        "        'smoke': [smoke],\n",
        "        'alco': [alco],\n",
        "        'active': [active],\n",
        "        'gender': [gender]\n",
        "    })\n",
        "\n",
        "    # BMI 계산\n",
        "    input_df['BMI'] = input_df['weight'] / ((input_df['height'] / 100) ** 2)\n",
        "\n",
        "    # 입력 순서 맞추기 (모델 학습 때 컬럼 순서와 동일해야 함)\n",
        "    feature_cols = ['age', 'ap_hi', 'ap_lo', 'height', 'weight',\n",
        "                    'cholesterol_2', 'cholesterol_3', 'gluc_2', 'gluc_3',\n",
        "                    'smoke', 'alco', 'active', 'gender', 'BMI']\n",
        "    input_df = input_df[feature_cols]\n",
        "\n",
        "    # 스케일링\n",
        "    X_input_scaled = scaler.transform(input_df)\n",
        "\n",
        "    # 발병 확률 예측\n",
        "    prob = clf_finetune.predict_proba(X_input_scaled)[0][1]"
      ],
      "metadata": {
        "id": "9VFd4OrnOLWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위험 요인 진단 및 개선 제안\n",
        "    suggestions = []\n",
        "    targets = {}\n",
        "    if ap_hi > 120:\n",
        "        suggestions.append(\"수축기 혈압 낮추기\")\n",
        "        targets['ap_hi'] = 120\n",
        "    if ap_lo > 80:\n",
        "        suggestions.append(\"이완기 혈압 낮추기\")\n",
        "        targets['ap_lo'] = 80\n",
        "    if input_df['BMI'].values[0] > 24.9:\n",
        "        suggestions.append(\"BMI 줄이기 (체중 감량)\")\n",
        "        targets['BMI'] = 24.9\n",
        "    if cholesterol > 1:\n",
        "        suggestions.append(\"콜레스테롤 개선\")\n",
        "        targets['cholesterol'] = 1\n",
        "    if gluc > 1:\n",
        "        suggestions.append(\"혈당 개선\")\n",
        "        targets['gluc'] = 1\n",
        "    if smoke == 1:\n",
        "        suggestions.append(\"금연\")\n",
        "    if alco == 1:\n",
        "        suggestions.append(\"음주 줄이기\")\n",
        "    if active == 0:\n",
        "        suggestions.append(\"운동량 늘리기\")\n",
        "\n",
        "    with out:\n",
        "        print(f\"예측된 심혈관 질환 발병 확률: {prob*100:.2f}%\")\n",
        "        if suggestions:\n",
        "            print(\"개선이 권장되는 항목:\")\n",
        "            for s in suggestions:\n",
        "                print(\"-\", s)\n",
        "            print(\"\\n개선 목표값:\")\n",
        "            for k, v in targets.items():\n",
        "                print(f\"  {k} : {v}\")\n",
        "        else:\n",
        "            print(\"현재 위험 요인은 크게 없습니다. 꾸준히 건강 관리하세요!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "9J9gDOg-Orb5",
        "outputId": "46046359-ab10-4c22-f6d5-6308c314d561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-95-01ba425e511b>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-95-01ba425e511b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    suggestions = []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인터랙티브 UI 생성\n",
        "ui = VBox([age_slider, ap_hi_slider, ap_lo_slider, height_slider, weight_slider,\n",
        "           cholesterol_dropdown, gluc_dropdown, smoke_dropdown, alco_dropdown, active_dropdown, gender_dropdown])\n",
        "\n",
        "button = Button(description=\"예측 및 개선안 보기\")\n",
        "button.on_click(lambda b: predict_and_suggest(\n",
        "    age_slider.value, ap_hi_slider.value, ap_lo_slider.value,\n",
        "    height_slider.value, weight_slider.value,\n",
        "    cholesterol_dropdown.value, gluc_dropdown.value,\n",
        "    smoke_dropdown.value, alco_dropdown.value,\n",
        "    active_dropdown.value, gender_dropdown.value))\n",
        "\n",
        "display(ui, button, out)"
      ],
      "metadata": {
        "id": "Vxg-PsyJOk_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aj6ISfiGOQ25"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}